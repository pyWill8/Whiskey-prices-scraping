{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bottles(bottles):\n",
    "\n",
    "    bottle_ids = bottles.find_all(\"h6\")                                      \n",
    "    bottle_names = bottles.find_all(\"h4\", text=re.compile(\"Macallan.*\")) # So that im just getting the bottles and no other tags\n",
    "    \n",
    "    all_bottles_prices = bottles.find_all(class_= [\"sold\", \"bndone\", \"openprice\", \"unsold\"]) # So that we have all bottles, sold and not sold. \n",
    "    \n",
    "    put_together = list(zip(bottle_ids, bottle_names, all_bottles_prices)) # putting all the info into a list\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(put_together, columns=[\"Lot number\", \"Name\", \"Price\"])\n",
    "    for i in df.columns:\n",
    "        df[i] = df[i].apply(lambda x: BeautifulSoup(str(x), \"lxml\").get_text())\n",
    "    #df = df.loc[~df[\"Price\"].str.contains(\"This lot is no longer available\")]  # Getting just sold bottles WILL NEED MOVING ELSEWHERE LATER\n",
    "\n",
    "    return df\n",
    "\n",
    "#bottles = soup\n",
    "#df = find_bottles(bottles)\n",
    "#df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['auctions/14-the-inaugural-auction/', 'auctions/15-the-second-auction/', 'auctions/18-the-third-auction/', 'auctions/23-the-fourth-auction/', 'auctions/27-the-fifth-auction/', 'auctions/29-the-sixth-auction/', 'auctions/30-the-seventh-auction/', 'auctions/31-the-eighth-auction/', 'auctions/33-the-ninth-auction/', 'auctions/34-the-10th-auction/', 'auctions/37-the-11th-auction/', 'auctions/38-the-12th-auction/', 'auctions/39-the-13th-auction/', 'auctions/40-the-14th-auction/', 'auctions/43-the-15th-auction/', 'auctions/44-the-16th-auction/', 'auctions/45-the-17th-auction/', 'auctions/46-the-18th-auction/', 'auctions/47-the-19th-auction/', 'auctions/48-the-20th-auction/', 'auctions/49-the-21st-auction/', 'auctions/50-the-22nd-auction/', 'auctions/51-the-23rd-auction/', 'auctions/53-the-24th-auction/', 'auctions/55-the-25th-auction/', 'auctions/56-the-26th-auction/', 'auctions/58-the-27th-auction/', 'auctions/59-the-28th-auction/', 'auctions/60-the-29th-auction/', 'auctions/61-the-30th-auction/', 'auctions/62-the-31st-auction/', 'auctions/63-the-32nd-auction/', 'auctions/64-the-33rd-auction/', 'auctions/65-the-34th-auction/', 'auctions/66-the-35th-auction/', 'auctions/67-the-36th-auction/', 'auctions/68-the-37th-auction/', 'auctions/69-the-38th-auction/', 'auctions/70-the-39th-auction/', 'auctions/71-the-40th-auction/', 'auctions/72-the-41st-auction/', 'auctions/73-the-42nd-auction/', 'auctions/74-the-43rd-auction/', 'auctions/79-the-44th-auction/', 'auctions/80-the-45th-auction/', 'auctions/81-the-46th-auction/', 'auctions/84-the-47th-auction/', 'auctions/85-the-48th-auction/', 'auctions/87-the-49th-auction/', 'auctions/88-the-50th-auction/', 'auctions/89-the-51st-auction/', 'auctions/90-the-52nd-auction/', 'auctions/91-the-53rd-auction/', 'auctions/92-the-54th-auction/', 'auctions/93-the-55th-auction/', 'auctions/94-the-56th-auction/', 'auctions/95-the-57th-auction/', 'auctions/96-the-58th-auction/', 'auctions/97-the-59th-auction/', 'auctions/98-the-60th-auction/', 'auctions/99-the-61st-auction/', 'auctions/100-the-62nd-auction/', 'auctions/101-the-63rd-auction/', 'auctions/102-the-64th-auction/', 'auctions/103-the-65th-auction/', 'auctions/104-the-66th-auction/', 'auctions/105-the-67th-auction/', 'auctions/106-the-68th-auction/', 'auctions/107-the-69th-auction/', 'auctions/108-the-70th-auction/', 'auctions/109-the-71st-auction/', 'auctions/110-the-72nd-auction/', 'auctions/111-the-73rd-auction/', 'auctions/112-the-74th-auction/', 'auctions/113-the-75th-auction/', 'auctions/114-the-76th-auction/', 'auctions/115-the-77th-auction/', 'auctions/116-the-78th-auction/', 'auctions/117-the-79th-auction/', 'auctions/135-2017-charity-auction/', 'auctions/118-the-80th-auction/', 'auctions/119-the-81st-auction/', 'auctions/120-the-82nd-auction/', 'auctions/121-the-83rd-auction/', 'auctions/122-the-84th-auction/', 'auctions/123-the-85th-auction/', 'auctions/124-the-86th-auction/', 'auctions/125-the-87th-auction/', 'auctions/126-the-88th-auction/', 'auctions/136-the-ben-2018-charity-auction/', 'auctions/127-the-89th-auction/', 'auctions/128-the-90th-auction/', 'auctions/129-the-91st-auction/', 'auctions/130-the-92nd-auction/', 'auctions/131-the-93rd-auction/', 'auctions/133-the-94th-auction-/', 'auctions/134-the-95th-auction/', 'auctions/137-the-96th-auction/', 'auctions/138-the-97th-auction/', 'auctions/139-the-98th-auction/', 'auctions/140-the-99th-auction/', 'auctions/141-the-100th-auction/', 'auctions/142-the-101st-auction/', 'auctions/143-the-102nd-auction/', 'auctions/144-the-103rd-auction/', 'auctions/145-the-104th-auction/', 'auctions/146-the-105th-auction/', 'auctions/147-the-106th-auction/', 'auctions/148-the-107th-auction/', 'auctions/149-the-108th-auction/', 'auctions/150-the-109th-auction/', 'auctions/151-the-110th-auction/', 'auctions/152-the-111th-auction/', 'auctions/153-the-112th-auction/', 'auctions/155-the-113th-auction/', 'auctions/156-the-114th-auction/', 'auctions/157-the-115th-auction/', 'auctions/158-the-116th-auction/', 'auctions/159-the-117th-auction/', 'auctions/160-the-118th-auction/', 'auctions/161-the-119th-auction/', 'auctions/162-the-120th-auction/', 'auctions/163-the-121st-auction/', 'auctions/164-the-122nd-auction/', 'auctions/165-the-123rd-auction/', 'auctions/166-the-124th-auction/', 'auctions/167-the-125th-auction/', 'auctions/169-the-126th-auction/', 'auctions/171-the-127th-auction/', 'auctions/172-the-128th-auction/', 'auctions/173-the-129th-auction/', 'auctions/174-the-130th-auction/', 'auctions/175-the-131st-auction/', 'auctions/176-the-132nd-auction/', 'auctions/177-the-133rd-auction/', 'auctions/178-the-134th-auction/', 'auctions/179-the-135th-auction/', 'auctions/180-the-136th-auction/', 'auctions/181-the-137th-auction/', 'auctions/183-the-138th-auction/', 'auctions/184-the-139th-auction/']\n"
     ]
    }
   ],
   "source": [
    "link2 = \"https://www.scotchwhiskyauctions.com/auctions/\" \n",
    "webpage_response2 = requests.get(link2)\n",
    "\n",
    "webpage2 = webpage_response2.content\n",
    "soup2 = BeautifulSoup(webpage2, \"lxml\")\n",
    "\n",
    "auction_links = [i[\"href\"] for i in soup2.find_all(\"a\", class_=\"auction\", href=True)] # Getting the auction links\n",
    "auction_links.reverse()\n",
    "x = auction_links[79:85]\n",
    "print(auction_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link = \"https://www.scotchwhiskyauctions.com/auctions/181-the-137th-auction/?page=1\"\n",
    "#webpage_response =requests.get(link)\n",
    "#\n",
    "#webpage = webpage_response.content\n",
    "#soup = BeautifulSoup(webpage, \"lxml\")\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Lot number\", \"Name\", \"Price\"])\n",
    "count = 0\n",
    "auction_count = 0\n",
    "if __name__ == \"__main__\":\n",
    "    # Iterating through all the auctions\n",
    "    for auction in auction_links:#NEED TO CHANGE BACK\n",
    "        print(\"-----\") # Make the terminal a bit easier to read\n",
    "        auction_count += 1\n",
    "        print(f\"Auction number: {auction_count}\")\n",
    "        \n",
    "        webpage_response = requests.get(\"https://www.scotchwhiskyauctions.com/\" + auction + \"?q=macallan&search=c\") #   Getting a auction page\n",
    "\n",
    "        webpage = webpage_response.content\n",
    "        soup = BeautifulSoup(webpage, \"lxml\")\n",
    "\n",
    "        # Getting the number of pages for each auction\n",
    "        number_pages_tag = soup.find_all(\"option\")\n",
    "        total_auction_pages_list = [i.text for i in number_pages_tag][-3].split() # Getting the pages string, and putting in a list to get the last value\n",
    "        \n",
    "        number_of_pages = total_auction_pages_list[-1] # Getting the pages last value (being the total number of pages on that auction, or \"page\" if there was only one page)\n",
    "        print(number_of_pages)\n",
    "        \n",
    "        # The reason why we have a try and except clause is to account for the fact that some pages only have one page, so if we arent returned a number of pages we want to just scrape once, which is what the except is doing. \n",
    "        try: \n",
    "            for page in range(1, int(number_of_pages)+1): # Has to be +1 as we have zero indexing. \n",
    "                link = \"https://www.scotchwhiskyauctions.com/\"\n",
    "                link = link + auction + \"?q=macallan&search=c\" + \"&page=\" + str(page)\n",
    "                webpage_response = requests.get(link)\n",
    "\n",
    "\n",
    "                webpage = webpage_response.content\n",
    "                soup = BeautifulSoup(webpage, \"lxml\")\n",
    "\n",
    "                current_page = find_bottles(soup)\n",
    "                df = pd.concat([df, current_page], ignore_index=True)\n",
    "\n",
    "                time.sleep(1) \n",
    "                count += 1\n",
    "                print(f\"Scraped: {count} pages\")\n",
    "        except:\n",
    "            link = \"https://www.scotchwhiskyauctions.com/\"\n",
    "\n",
    "            # In this one we dont have the page number\n",
    "            link = link + auction + \"?q=macallan&search=c\"    \n",
    "            webpage_response = requests.get(link)\n",
    "            webpage = webpage_response.content\n",
    "            soup = BeautifulSoup(webpage, \"lxml\")\n",
    "\n",
    "            current_page = find_bottles(soup)\n",
    "            df = pd.concat([df, current_page], ignore_index=True)\n",
    "            \n",
    "            time.sleep(1) \n",
    "            count += 1\n",
    "            print(f\"Scraped: {count} pages\")\n",
    "        \n",
    "\n",
    "print(df)\n",
    "\n",
    "#df.to_csv(\"Macallan_whisky.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e840f835684bb817df5906e8ed510f836174b639f32d5b8a3998d784828aaa2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
